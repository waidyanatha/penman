{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b49014",
   "metadata": {},
   "source": [
    "# Load and Embed PDF artciles\n",
    "[Following](https://www.linkedin.com/pulse/build-lightning-fast-rag-chatbot-powered-groqs-lpu-ollama-multani-ssloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a805a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community import embeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# from google.colab import userdata\n",
    "import os\n",
    "import time\n",
    "import textwrap\n",
    "import gradio as gr\n",
    "\n",
    "__groq_api_key__ = os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51de760",
   "metadata": {},
   "source": [
    "## Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0c28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "data_dir = \"/home/nuwan/workspace/penman/wrangler/data/article/stock/cap\"\n",
    "loader = PyPDFDirectoryLoader(data_dir)\n",
    "\n",
    "the_text = loader.load()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2d846",
   "metadata": {},
   "source": [
    "## Splitting Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71e66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "chunks = text_splitter.split_documents(the_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335b5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "\n",
    "    documents=chunks,\n",
    "\n",
    "    collection_name=\"ollama_embeds\",\n",
    "\n",
    "    embedding=OllamaEmbeddings(model='nomic-embed-text'),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a865a6",
   "metadata": {},
   "source": [
    "## Setting Up Groq's LPU for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9df61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# from google.colab import userdata\n",
    "\n",
    "# groq_api_key = userdata.get('groq_api_key')\n",
    "\n",
    "llm = ChatGroq(\n",
    "\n",
    "            groq_api_key=__groq_api_key__,\n",
    "\n",
    "            model_name='mixtral-8x7b-32768'\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdb075",
   "metadata": {},
   "source": [
    "## Building the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add67f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "rag_template = \"\"\"...\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b16107",
   "metadata": {},
   "source": [
    "## Testing the RAG Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec31e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm here to help! To provide the best assistance, could you please provide me\n",
      "with a little more information about what you're looking for? For example, are\n",
      "you interested in learning a new programming language, do you need help with a\n",
      "specific coding problem, or are you looking for resources to learn about a\n",
      "particular technology? I'm here to answer any questions you have to the best of\n",
      "my ability.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"What is this document about\")\n",
    "print(textwrap.fill(response, width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d6d1b",
   "metadata": {},
   "source": [
    "## Launching the Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83d1e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(user_question):\n",
    "    # Processing and response time measurement here\n",
    "    iface = gr.Interface(fn=process_question,\n",
    "                         inputs=gr.Textbox(lines=2, placeholder=\"Type your question here...\"),\n",
    "                         outputs=gr.Textbox(),\n",
    "                         title=\"GROQ CHAT\",\n",
    "                         description=\"Ask any question about your document, and get an answer along with the response time.\")\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5e3275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_127963/258990194.py\", line 3, in process_question\n",
      "    iface = gr.Interface(fn=process_question,\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 268, in __init__\n",
      "    self.main_input_components = [\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 269, in <listcomp>\n",
      "    get_component_instance(i, unrender=True) for i in inputs\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/components/base.py\", line 456, in get_component_instance\n",
      "    elif unrender and component_obj.is_rendered:\n",
      "AttributeError: 'Textbox' object has no attribute 'is_rendered'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio/flagged/dataset1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_127963/258990194.py\", line 3, in process_question\n",
      "    iface = gr.Interface(fn=process_question,\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 268, in __init__\n",
      "    self.main_input_components = [\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 269, in <listcomp>\n",
      "    get_component_instance(i, unrender=True) for i in inputs\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/components/base.py\", line 456, in get_component_instance\n",
      "    elif unrender and component_obj.is_rendered:\n",
      "AttributeError: 'Textbox' object has no attribute 'is_rendered'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_127963/258990194.py\", line 3, in process_question\n",
      "    iface = gr.Interface(fn=process_question,\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 268, in __init__\n",
      "    self.main_input_components = [\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 269, in <listcomp>\n",
      "    get_component_instance(i, unrender=True) for i in inputs\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/components/base.py\", line 456, in get_component_instance\n",
      "    elif unrender and component_obj.is_rendered:\n",
      "AttributeError: 'Textbox' object has no attribute 'is_rendered'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_127963/258990194.py\", line 3, in process_question\n",
      "    iface = gr.Interface(fn=process_question,\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 268, in __init__\n",
      "    self.main_input_components = [\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 269, in <listcomp>\n",
      "    get_component_instance(i, unrender=True) for i in inputs\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/components/base.py\", line 456, in get_component_instance\n",
      "    elif unrender and component_obj.is_rendered:\n",
      "AttributeError: 'Textbox' object has no attribute 'is_rendered'\n"
     ]
    }
   ],
   "source": [
    "user_question = \"what is cap?\"\n",
    "process_question(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ea43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
