{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b49014",
   "metadata": {},
   "source": [
    "# Load and Embed PDF artciles\n",
    "* [Following](https://www.linkedin.com/pulse/build-lightning-fast-rag-chatbot-powered-groqs-lpu-ollama-multani-ssloc)\n",
    "* [Dockerized chromadb](https://medium.com/@pierrelouislet/getting-started-with-chroma-db-a-beginners-tutorial-6efa32300902)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b3f81f-58cd-4e11-bdc8-4a67379ab6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore')     #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; else set it to False to turn off debugging mode '''\n",
    "debug = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07a805a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libs loaded!\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "# from langchain_community.document_loaders import TextLoader, PyPDFDirectoryLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community import embeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# from google.colab import userdata\n",
    "# import os\n",
    "import time\n",
    "import textwrap\n",
    "import gradio as gr\n",
    "''' fix the problem with sqllite warning '''\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "# \n",
    "__groq_api_key__ = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "print(\"All libs loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97703e49-acda-46f8-8607-58380a1c1cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional VECTORDB-libraries in LOADER-package of ETL-module imported successfully!\n",
      "All functional VECTORIZE_PDF-libraries in STOCK-package of ARTICLE-module imported successfully!\n",
      "__propAttr__ Class initialization complete\n",
      "\n",
      "read pdf files in folder and store as vectors class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "proj_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(1,proj_dir.split('wrangler/')[0])\n",
    "from rezaware.modules.etl.loader import vectorDB as vec\n",
    "from wrangler.modules.article.stock import vectorize_pdf as vpdf\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    vec = importlib.reload(vec)\n",
    "    vpdf= importlib.reload(vpdf)\n",
    "\n",
    "__desc__ = \"read pdf files in folder and store as vectors\"\n",
    "clsPDF = vpdf.dataWorkLoads(desc=__desc__)\n",
    "__db_type__ = \"chromadb\"\n",
    "__chromadb_dir__ = \"/home/nuwan/workspace/penman/wrangler/data/article/stock/\"\n",
    "clsVDB = vec.dataWorkLoads(desc=__desc__, db_type=__db_type__, db_root=__chromadb_dir__)\n",
    "\n",
    "print(\"\\n%s class initialization and load complete!\" % __desc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51de760",
   "metadata": {},
   "source": [
    "## Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019d686f-8cbc-44b6-8736-5f337c3f5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78 text pages\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/nuwan/workspace/penman/wrangler/data/article/stock/cap\"\n",
    "the_text=clsPDF.load_pdf_files(\n",
    "    folder_path=data_dir\n",
    ")\n",
    "print(\"Loaded %d text pages\" % len(the_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2d846",
   "metadata": {},
   "source": [
    "## Splitting Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aea5c49-f538-4a73-bf5e-808b8ec1d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 78 docs into 181 chunks\n"
     ]
    }
   ],
   "source": [
    "chunks = clsPDF.text_to_chunks(\n",
    "    text = the_text\n",
    ")\n",
    "print(\"Split %d docs into %d chunks\" % (len(the_text),len(chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e80303-8b54-4f4f-9469-73824f79993c",
   "metadata": {},
   "source": [
    "## Setting up the ChromaDB collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc69c109-2c91-470e-9fd8-aebf052420b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLLAMA_EMBEDS collection exists; reading documents\n",
      "Created OLLAMA_EMBEDS collection with 181 embeddings\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "# __db_type__ = \"chromadb\"\n",
    "__db_name__ = \"cap\"\n",
    "# __chromadb_dir__ = \"/home/nuwan/workspace/penman/wrangler/data/article/stock/\"\n",
    "__collection__= \"ollama_embeds\"\n",
    "_embedding_fn = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "if __collection__ not in [x.name for x in clsVDB.get_collections(db_name = __db_name__)]:\n",
    "    print(\"creating document collection %s\" % __collection__.upper())\n",
    "    print(clsVDB.get_collections(db_name = __db_name__))\n",
    "    vectorstore=clsVDB.store_vectors(\n",
    "        documents=chunks,\n",
    "        db_name = __db_name__,\n",
    "        collection = __collection__,\n",
    "        embedding_fn=_embedding_fn,\n",
    "    )\n",
    "else:\n",
    "    print(\"%s collection exists; reading documents\" % __collection__.upper())\n",
    "    vectorstore=clsVDB.read_vectors(\n",
    "        db_name = __db_name__,\n",
    "        collection = __collection__,\n",
    "        embedding_fn=_embedding_fn,        \n",
    "    )\n",
    "print(\"Created %s collection with %d embeddings\" \n",
    "      % (vectorstore._collection.name.upper(), vectorestore._collection.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65a32a28-28c2-4001-b0e6-20e20f183d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': '/home/nuwan/workspace/penman/wrangler/data/article/stock/cap/Waidy_S12-strat-opport-challenge_CAP_v20131129.pdf'}, page_content='□Why do we need CAP\\n□What is CAP?\\n□How do we use it?\\n■CAP-Profile\\n■Register of Alerting \\nAuthorities\\n■Multi agency situational \\nawareness\\n□Automation\\n□Pilots\\n□Users\\n□Conclusion\\n□ResourcesOutline'),\n",
       " Document(metadata={'page': 6, 'source': '/home/nuwan/workspace/penman/wrangler/data/article/stock/cap/ITU-D_workshop_CAP_report_waidyanatha.pdf'}, page_content='CAP workshop report Version 1.0\\n 4.Objectives of the CAP standard\\nCAP was developed by Art Botterell et al11 (2006) with an all-hazards all-media approach. A key benefit of CAP  \\nfor sending alert messages is that the sender can activate multiple warning systems with a single input. Using a  \\nsingle input reduces the cost and complexity of notifying many warning systems. A single input message also  \\nprovides consistency in the information delivered over multiple systems. People receive exact corroboration of  \\nthe warning through multiple channels. This is very important, as research has found that people do not typically  \\nact on the first warning signal but begin looking for confirmation. Only when convinced that the warning is not a  \\nfalse alarm, do they act on it.\\nThe corroboration and intention to act on an alert is based on the trusted alert source. A trusted alert source is'),\n",
       " Document(metadata={'page': 32, 'source': '/home/nuwan/workspace/penman/wrangler/data/article/stock/cap/Waidy_S12-strat-opport-challenge_CAP_v20131129.pdf'}, page_content='Conclusion\\nCAP is a consistent, complete, multi lingual, and interoperable global \\nemergency communication protocol\\nCAP offers standard guidelines for developing an inventory of \\nemergency information templates and messages \\nCAP should be adopted by states and organizations for their public and \\nclosed-user-group exchange of emergency information\\nStates or organization must first develop a CAP Profile in consultation \\nwith all involved stakeholders; as a first step – register alerting \\nauthorities\\nProfile should consider the target – audience (<s cope>), jurisdictions \\n<area>, <Language>, Technologies, and Country specific \\nPublisher/Subscriber rules\\nAlerting agencies should adopt a “CAP Broker” for constructing and \\nissuing CAP messages via “tested” technologies\\nRecommendation to Disaster Communications Technology \\nManufacturers – Make your equipment CAP compliant'),\n",
       " Document(metadata={'page': 26, 'source': '/home/nuwan/workspace/penman/wrangler/data/article/stock/cap/Waidy_S12-strat-opport-challenge_CAP_v20131129.pdf'}, page_content='CAP-AU (Australian) Initiative')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(\"What is CAP?\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a865a6",
   "metadata": {},
   "source": [
    "## Setting Up Groq's LPU for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9df61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "            groq_api_key=__groq_api_key__,\n",
    "            model_name='mixtral-8x7b-32768'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdb075",
   "metadata": {},
   "source": [
    "## Building the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "add67f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "rag_template = \"\"\"Answer this question using the provided context only.\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b16107",
   "metadata": {},
   "source": [
    "## Testing the RAG Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec31e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document appears to be about the Common Alerting Protocol (CAP) and its\n",
      "implementation in XML format. According to the document, CAP is a \"simple and\n",
      "general\" format for exchanging public warnings and emergencies between alerting\n",
      "systems. The document provides a detailed description of the various components\n",
      "of a CAP message, including the alert, info, resource, and area blocks, as well\n",
      "as the different elements that can be included in each block. The document also\n",
      "mentions the use of XML schemas for validating the structure of CAP messages.\n",
      "The document also appears to discuss the use of the Sahana Tools, specifically\n",
      "the Community Resilience Mapping Tool (CRMT), Alerting and Messaging Broker\n",
      "(SAMBRO), and Incident Reporting System (IRS), which are developed on the Sahana\n",
      "Eden Python and Web2Py platform and share common libraries. There is also a\n",
      "figure that provides an overview of the Alerting Protocol (EDXL-CAP) voice-text\n",
      "alerts.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"what is this document about?\")\n",
    "print(textwrap.fill(response, width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d6d1b",
   "metadata": {},
   "source": [
    "## Launching the Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83d1e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(user_question):\n",
    "    # Processing and response time measurement here\n",
    "    iface = gr.Interface(\n",
    "        fn=process_question,\n",
    "        inputs=gr.Textbox(lines=2,\n",
    "                          placeholder=\"Type your question here...\"),\n",
    "        outputs=gr.Textbox(),\n",
    "        title=\"GROQ CHAT\",\n",
    "        description=\"Ask any question about your document, and get an answer along with the response time.\")\n",
    "    iface.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a5e3275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_327475/3393144403.py\", line 3, in process_question\n",
      "    iface = gr.Interface(\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 268, in __init__\n",
      "    self.main_input_components = [\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/interface.py\", line 269, in <listcomp>\n",
      "    get_component_instance(i, unrender=True) for i in inputs\n",
      "  File \"/home/nuwan/.cache/pypoetry/virtualenvs/penman-UgVLv5KY-py3.10/lib/python3.10/site-packages/gradio/components/base.py\", line 456, in get_component_instance\n",
      "    elif unrender and component_obj.is_rendered:\n",
      "AttributeError: 'Textbox' object has no attribute 'is_rendered'\n"
     ]
    }
   ],
   "source": [
    "user_question = \"what is cap?\"\n",
    "process_question(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ea43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
